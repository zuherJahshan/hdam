{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import json\n",
    "\n",
    "from hdam import HDAM\n",
    "from reads import Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet  = ['A', 'C', 'G', 'T', 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random patterns of size k over the alphabet {A,C,G,T}\n",
    "def generate_patterns(num_of_patterns, pattern_length):\n",
    "    patterns = []\n",
    "    for _ in range(num_of_patterns):\n",
    "        pattern = \"\".join(np.random.choice([\"A\", \"C\", \"G\", \"T\"], size=pattern_length))\n",
    "        patterns.append(pattern)\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"data/genomes/\"\n",
    "database_viruses = [\n",
    "    \"chickenpox\",\n",
    "    \"dengue\",\n",
    "    \"ebola\",\n",
    "    \"herpes\",\n",
    "    \"kyasanur\",\n",
    "    \"marburg\",\n",
    "    \"measles\",\n",
    "    \"sars-cov-2\"    \n",
    "]\n",
    "\n",
    "other_viruses = [\n",
    "    \"crimea-congo\",\n",
    "    \"hantavirus\",\n",
    "    \"influenza\",\n",
    "    \"junin\",\n",
    "    \"lassa\",\n",
    "    \"machupo\",\n",
    "    \"papiloma\",\n",
    "    \"rotavirus\",\n",
    "]\n",
    "\n",
    "kmer_length = 21\n",
    "number_of_reads = 1000\n",
    "read_length = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_filepath = []\n",
    "for idx, reference in enumerate(database_viruses):\n",
    "    references_filepath.append(dirpath + reference + \".fna\")\n",
    "\n",
    "other_filepath = []\n",
    "for idx, reference in enumerate(other_viruses):\n",
    "    other_filepath.append(dirpath + reference + \".fna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Sanity Functions ################\n",
    "\n",
    "# extract genome from fasta, accounting for all contigs, output a list of contings\n",
    "def extract_genome_from_fasta(fasta_file):\n",
    "    genome = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        genome.append(str(record.seq).upper())\n",
    "    return genome\n",
    "\n",
    "\n",
    "def get_genome_length(genome):\n",
    "    return sum([len(contig) for contig in genome])\n",
    "\n",
    "\n",
    "# return the length of the longest matching string between a reference and a read\n",
    "def longest_match(reference, read):\n",
    "    max_match = 0\n",
    "    for i in range(len(read)):\n",
    "        for j in range(len(reference)):\n",
    "            match = 0\n",
    "            while i + match < len(read) and j + match < len(reference) and read[i + match] == reference[j + match]:\n",
    "                match += 1\n",
    "            max_match = max(max_match, match)\n",
    "    return max_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "viruses_and_lengths = []\n",
    "for file in glob.glob(\"data/genomes/*.fna\"):\n",
    "    genome = extract_genome_from_fasta(file)\n",
    "    # print(get_genome_length(genome))\n",
    "    viruses_and_lengths.append((file.split(\"/\")[-1].split(\".\")[0], get_genome_length(genome)))\n",
    "viruses_and_lengths.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viruses_and_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kmers_from_fasta(fasta_file, kmer_length, overall_size):\n",
    "    kmers = []\n",
    "\n",
    "    # Parse the FASTA file\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequence = str(record.seq).upper()\n",
    "        \n",
    "        # Generate kmers for each contig\n",
    "        for i in range(len(sequence) - kmer_length + 1):\n",
    "            kmer = sequence[i:i + kmer_length]\n",
    "            kmers.append(kmer)\n",
    "\n",
    "    stride = len(kmers) // overall_size\n",
    "    if stride == 0:\n",
    "        return kmers\n",
    "    else:\n",
    "        return [kmer for idx, kmer in enumerate(kmers) if idx % stride == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads = Reads(\"data\", read_length=read_length)\n",
    "hdam = HDAM(pattern_length=kmer_length, alphabet=alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_size = 2048\n",
    "for virus, reference in zip(database_viruses, references_filepath):\n",
    "    hdam.save(virus, extract_kmers_from_fasta(reference, kmer_length, database_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reverse_complements(sequences):\n",
    "    reverse_complements = []\n",
    "    for sequence in sequences:\n",
    "        complement = {\"A\": \"T\", \"C\": \"G\", \"G\": \"C\", \"T\": \"A\"}\n",
    "        reverse_complements.append(\"\".join([complement.get(base, \"N\") for base in sequence[::-1]]))\n",
    "    return reverse_complements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The structure of the raw results should be as follows:\n",
    "raw_results[platform][threshold][virus][\"results_type, i.e. rc or ord\"] = List[viruses] || None\n",
    "'''\n",
    "def add_raw_result(raw_results, platform, threshold, virus, results_type, results):\n",
    "    curr_res_ptr = raw_results\n",
    "    if not platform in raw_results:\n",
    "        curr_res_ptr[platform] = {}\n",
    "    curr_res_ptr = raw_results[platform]\n",
    "    if not threshold in curr_res_ptr:\n",
    "        curr_res_ptr[threshold] = {}\n",
    "    curr_res_ptr = curr_res_ptr[threshold]\n",
    "    if not virus in curr_res_ptr:\n",
    "        curr_res_ptr[virus] = {}\n",
    "    curr_res_ptr = curr_res_ptr[virus]\n",
    "    curr_res_ptr[results_type] = results\n",
    "    return raw_results\n",
    "\n",
    "def write_raw_results_to_file(raw_results, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(raw_results, f)\n",
    "\n",
    "def read_raw_results_from_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reads(reads, read_length):\n",
    "    preprocessed = []\n",
    "    for read in reads:\n",
    "        if len(read) < read_length:\n",
    "            continue\n",
    "        else:\n",
    "            preprocessed.append(read[:read_length])\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platforms = [\"pacbio0\", \"pacbio5\", \"pacbio10\", \"pacbio15\"] # \"illumina\", \"roche\"\n",
    "raw_results = {}\n",
    "\n",
    "for platform in platforms:\n",
    "    for threshold in range(0, 22):\n",
    "        hdam.set_threshold(threshold)\n",
    "        for virus, reference in zip(database_viruses + other_viruses, references_filepath + other_filepath):\n",
    "            search_patterns = reads.getReads(platform, reference, reads_num=number_of_reads)\n",
    "            search_patterns = preprocess_reads(search_patterns, read_length)\n",
    "            rc_search_patterns = generate_reverse_complements(search_patterns)\n",
    "            results = hdam.search(search_patterns, read_length)\n",
    "            rc_results = hdam.search(rc_search_patterns, read_length)\n",
    "            add_raw_result(raw_results, platform, threshold, virus, \"reads\", results)\n",
    "            add_raw_result(raw_results, platform, threshold, virus, \"rc_reads\", rc_results)\n",
    "            write_raw_results_to_file(raw_results, \"raw_results.json\")\n",
    "            print(f\"Finished searching for {virus} with platform {platform} and threshold {threshold}\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
